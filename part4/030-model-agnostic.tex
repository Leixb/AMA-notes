%! TEX root = ../000-main.tex
\chapter{Model-agnostic interpretability methods}
\chaptermark{IML agnostic}

\section{Introduction}

Model-agnostic interpretation methods are those that only require
the evaluation of the fitted prediction model on the training set, on
the test set, or on perturbations of them.

No other information from the kind of model at hand is needed.

To be more formal, let $f$ be the prediction function estimated from a
training sample using a generic prediction model.

We assume that $f$ depends on $p$ arguments, so the predicted value
for $x = (x_1, \dots , x_p)$ is $f(x)$.

The only connection between the model-agnostic interpretation
methods and the prediction model is through the function $f$ and,
more specifically, only evaluations of $f$ at different points $x$ are
allowed.

Under this setting, to interpret the prediction model equals to
interpret the prediction function $f$.

This task is essentially the same we would have to do if we wanted
to explore a generic mathematical function $g$ depending on $p$
variables, from which only evaluations are allowed.

Therefore, any procedure that allows exploring a generic function $g$
(using only evaluations of $g$) can be considered a model-agnostic
method that could be used for interpreting a prediction function $f$.

For instance, computing a numerical approximation to the gradient
of $f$ at a point $x$ can be considered a model-agnostic interpretation
method, as well as using this approximation to compute the first
order Taylor expansion of $f$ around $x$.

Model-agnostic methods are specially useful for interpreting
prediction models for which there are no specific interpretation
methods.

Nevertheless, model-agnostic methods can also improve the
interpretation of models that are usually considered interpretable.

Even multiple linear regression could benefit from the application of
some model-agnostic methods.

When a new model-agnostic interpretation method is introduced, a
good practice is to check what it provides when applied to a classical
simple prediction model, as linear regression, logistic regression or
their additive extensions.

In these simple cases, sometimes it is possible to obtain the closed
expression of the new method results and then to relate them to the
standard outputs of the classical methods.

This way the new interpretation method will be either reinforced
(when its classical counterpart is a sensible measure) or called into
question (when the opposite happens).

\section{Global measures of variable relevance}

Let us consider the prediction problem involving the random
vector $(X,\,Z,\,Y),\;X\in\mathds{R}^p,\,Z\in\mathds{R},\,Y\in\mathds{R}$,
where $Y$ is the response variable that should be predicted from $(X,\,Z)$.

A \iemph{prediction function} $f : \mathds{R}^{p+1} \to \mathds{R}$ has
\emph{expected loss} (or \emph{risk}):
\begin{equation*}
	R(f(X,\,Z),\,Y) = \mathbb{E} \left[ L(f(X,\,Z),\,Y) \right]
\end{equation*}
where $L : \mathds{R}\times\mathds{R} \to \mathds{R}^+$ is a \iemph{loss function}
measuring the \emph{cost} associated with predicting $Y$ by $f(X,\,Z)$.

For instance, \iemph{quadratic loss} is defined as:
\begin{equation*}
	L(y,\,f(x,\,z)) = (y - f(x,\,z))^2
\end{equation*}

We consider the problem of measuring the effect of the single
variable $Z$ on the prediction function $f$ when predicting $Y$
by $f(X,\,Z)$. We call that effect the \iemph{variable relevance}
or \iemph{variable importance} of $Z$.

We assume that a training sample of size $n_1$ and
a test sample of size $n_2$ are available.

\subsection{Leave-one-covariate-out (LOCO)}

A simple approach to define the importance of the variable $Z$:
\begin{enumerate}
	\item Fit the model including both $X$ and $Z$.
	\item Fit the model including only $X$ (leave $Z$ out).
	\item The relevance of $Z$ by \iemph{LOCO} is given by the relative
	      decrease in the prediction accuracy when $Z$ is omitted from the model.
\end{enumerate}

This approach is used, for instance, in multiple linear regression
to decide if a variable should be included in the model or not.

\begin{note}
	The model must be fitted \emph{twice}
\end{note}

\subsubsection{Relevance by LOCO at a populational level}

It could happen that there would exists a natural reduced version of
$f$, say $f_p$, depending only on $p$ variables such that $f_p(X)$ would be the prediction
of $Y$ when $Z$ is not available.

For instance, the natural reduced version of $f(X,\,Z) = \beta_0 + X^T\beta_x + Z\beta_z$
could be $f_p(X) = \beta'_0 + X^T\beta'_x$ for some $\beta'_0,\,\beta'_x$ possibly
different from $\beta_0,\,\beta_x$.

In this case, the usual relevance measure of $Z$ is:
\begin{equation*}
	R(f_p(X),\,Y) - R(f(X,\,Z),\,Y) = \mathds{E} \left[ (Y - f_p(X))^2 - (Y - f(X,\,Z))^2 \right]
\end{equation*}
which corresponds to the reduction in the risk function when using $Z$.

An alternative measure of the relevance of $Z$ is:
\begin{equation*}
	\mathds{E}(L(f(X,\,Z),\,Y),f_p(X))) = \mathds{E} \left[ (f_p(X) - f(X,\,Z))^2 \right]
\end{equation*}

Both measures coincide under quadratic loss, when $(Y - f(X,\,Z))$ has zero mean
and it is independent of $(X,\,Z)$.

\begin{example}{Additive model}{}
	\begin{align*}
		Y                                   & = \beta_0 + s_1(X) + s_2(Z) + \varepsilon      \\[0.5em]
		f(X,\,Z) = \mathds{E}(Y \mid X,\,Z) & = \beta_0 + s_1(X) + s_2(Z)                    \\
		f_p(X) = \mathds{E}(Y \mid X)       & = \beta_0 + s_1(X) + \mathds{E}(s_2(Z) \mid X)
		= \beta_0 + s_1'(X)
	\end{align*}

	The relevance of $Z$ by LOCO is:
	\begin{equation*}
		\mathds{E}(L(f(X,\,Z),\,Y),f_p(X))) = \mathds{E} \left[ (s_2(Z) - \mathds{E}(s_2(Z) \mid X))^2 \right]
		= \mathds{E} \left[ \text{Var}(s_2(Z) \mid X)\right]
	\end{equation*}

	\tcbline

	Under additional linearity: $Y = \beta_0 + X^T\beta_X + Z\beta_Z + \varepsilon$,
	the relevance of $Z$ by LOCO is:
	\begin{equation*}
		\mathds{E}\left[ \text{Var}(Z \beta_Z \mid X)\right] = \beta_Z^2 \mathds{E}\left[ \text{Var}(Z \mid X)\right]
	\end{equation*}
\end{example}


\subsection{Variable importance by random permutations}

% TODO: cite
In the context of random forests (RF), Breiman (2001) proposed an
alternative to LOCO:
\emph{to randomly permute the values of the variable $Z$ in the test sample}
(the out-of-bag dataset in RF).

\begin{algorithm}{Variable importance by random permutations}{}
	\begin{enumerate}
		\item Fit the model with the training sample using all the original
		      explanatory variables, $X$ and $Z$.
		\item Evaluate the accuracy of the estimated model in the test sample using the observed values of
		      $X$ and $Z$.
		\item Replace the values of $Z$ in the test sample by a random permutation
		      $Z'$.
		\item Evaluate the accuracy of the estimated model in the test sample using the observed values of $X$
		      and the permuted values $Z'$.
		\item The relevance of $Z$ by \emph{random permutations} is given by the relative
		      decrease in the prediction accuracy when $Z$ is replaced by $Z'$.
	\end{enumerate}
	\tcblower
	\begin{note}
		Steps 3 and 4 can be repeated $n$ times and average the accuracy measures in step 5.
	\end{note}
	\begin{note}
		The model is \emph{estimated only once}.
	\end{note}
\end{algorithm}

\subsubsection{Random permutations at a population level}

The population counterpart of taking random permutations of values
of $Z$ in the test sample, is to \emph{replace the random variable $Z$ by and independent
	copy of it, $Z'$}. with the same marginal distribution as
$Z$ but independent from $(X,\,Y)$.

This approach does not require the reduced version $f_p$ of $f$.

In this way, the relevance measure of $Z$ will be:
\begin{equation*}
	\mathds{E}(L(f(X,\,Z),\,Y),f(X,\,Z')) = \mathds{E} \left[ (f(X,\,Z) - f(X,\,Z'))^2 \right]
\end{equation*}

\begin{example}{Additive model}{}
	Consider the case of $f$ being \emph{additive} in $X$ and $Z$:
	\begin{equation*}
		f(X,\,Z) = \beta_0 + s_1(X) + s_2(Z)
	\end{equation*}
	with $\mathds{E}(s_2(Z)) = 0$.

	Under \emph{quadratic loss}:
	\begin{align*}
		\mathds{E}(L(f(X,\,Z),\,Y),f(X,\,Z')) & = \mathds{E} \left[ (f(X,\,Z) - f(X,\,Z'))^2 \right] \\
		                                      & = \mathds{E} \left[
			\left(
			(\beta_0 + s_1(X) + s_2(Z)) - (\beta_0 + s_1(X) + s_2(Z'))
			\right)^2
			)
		\right]                                                                                      \\
		                                      & = 2\text{Var}(s_2(Z))
	\end{align*}

	if additional linearity happens, $s_2(Z) = Z\beta_Z$, then this relevance measure
	equals $2\beta_Z^2 \text{Var}(Z)$.
\end{example}

\subsubsection{Undesirable properties of random permutations}

At first glance, the relevance measures of $2\text{Var}(s_2(Z))$ and $2\beta_Z^2 \text{Var}(Z)$
seem to be suitable, but:
\begin{itemize}
	\item The relevance of $Z$ would be the same in two completely different scenarios:
	      \begin{enumerate}
		      \item $X$ and $Z$ are independent; $Z$ encode exclusive information about $Y$.
		      \item $X$ and $Z$ are strongly related; in such a case $X$ could make up for the
		            absence of $Z$.
	      \end{enumerate}
	      Clearly, $Z$ is more relevant in the first scenario, neither
	      $2\text{Var}(s_2(Z))$ nor $2\beta_Z^2 \text{Var}(Z)$ can distinguish between the two scenarios.
	      \begin{note}
		      This is not the case in relevance by LOCO which
		      is $\beta_Z^2 \mathds{E} \left[ \text{Var}(Z \mid X)\right]$.
	      \end{note}
	\item The replacement of $Z$ by an independent copy $Z'$ implies a drastic alteration
	      of the prediction function $f(X,\,Z)$.
	      \begin{itemize}
		      \item Consider again the simple case of the linear predictor
		            $f(X,\,Z) = \beta_0 + X^T\beta_X + Z\beta_Z$.
		      \item When replacing $Z$ by $Z'$, the prediction function becomes:
		            \begin{equation*}
			            f(X,\,Z') = \beta_0 + X^T\beta_X + Z'\beta_Z =
			            (\beta_0 - \mathds{E}(Z)\beta_Z) + X^T\beta_X + (Z' + \mathds{E}(Z))\beta_Z
		            \end{equation*}
		            which is equivalent to using the reduced version of $f$:
		            \begin{equation*}
			            f_p(X,\,Z') = \beta'_0 + X^T\beta_X + \nu
		            \end{equation*}
		            where $\beta'_0 = \beta_0 - \mathds{E}(Z)\beta_Z$ and $\nu = (Z' + \mathds{E}(Z))\beta_Z$ is
		            a random noise independent from $(X,\,Y)$, that does not help in any way to predict $Y$.
		      \item A preferred alternative would be to use the reduced version of $f$ directly:
		            \begin{equation*}
			            f_p(X,\,Z) = \beta'_0 + X^T\beta_X
		            \end{equation*}
		            which is equivalent to replacing $Z$ by $\mathds{E}(Z)$ and
		            $\beta'_0 = \beta_0 + \mathds{E}(Z)\beta_Z$.
	      \end{itemize}
	\item When $X$ and $Z$ are strongly related, there is a risk of
	      \emph{extrapolation} when evaluating $f(X,\,Z')$. This can happen since
	      the support of
	      $(X,\,Z)$ could be much smaller than the support of $(X,\,Z)$, which
	      is the Cartesian product of the supports $X$ and $Z$.
\end{itemize}

\subsection{Relevance by ghost variables}

We have seen that replacing $Z$ by $\mathds{E}(Z)$ in $f(X,\,Z)$ is
more appropriate than replacing $Z$ by an independent copy $Z'$ (random
permutations).

\begin{note}
	But, even better is to replace $Z$ by $\mathds{E}(Z \mid X)$:
	the best prediction of $Z$ as a function of $X$ according to the
	quadratic loss.
\end{note}

If there is dependence between $X$ and $Z$, then we expect $\left|Z - \mathds{E}(Z \mid X)\right|$
to be less than $\left|Z - \mathds{E}(Z)\right|$, so
$f(X,\,\mathds{E}(Z \mid X))$ should be closer to $f(X,\,Z)$ than
$f(X,\,\mathds{E}(Z))$.

Therefore, when $Z$ is not available, replacing it by $\mathds{E}(Z \mid X)$
allows $X$ to contribute a little bit more in the prediction of $Y$ than
when $Z$ is replaced by $\mathds{E}(Z)$.

The bigger the contribution of $X$ is, the smaller is the relevance of $Z$
in  the prediction of $Y$, measured by the quadratic loss:
\begin{equation*}
	\mathds{E}(L(f(X,\,Z),\,Y),f(X,\,\mathds{E}(Z \mid X))) =
	\mathds{E} \left[ (f(X,\,Z) - f(X,\,\mathds{E}(Z \mid X)))^2 \right]
\end{equation*}

\begin{marker}
	We call \iemph{ghost variable} of $Z$ any estimator of $\mathds{E}(Z \mid X)$.
\end{marker}

\begin{algorithm}{Relevance by ghost variables}{}
	\begin{enumerate}
		\item Fit the model with the training sample using all the original explanatory variables,
		      $X$ and $Z$.
		\item Evaluate the accuracy of the estimated model in the test sample using the observed values
		      of $X$ and $Z$.
		\item Define the \emph{ghost variable} of $Z$ as $\widehat{Z} = \widehat{\mathds{E}(Z \mid X)}$,
		      where the last estimation is done in the test sample.
		\item Evaluate the accuracy of the estimated model in the test sample using
		      the observed values of $X$ and the ghost variable $\widehat{Z}$.
		\item The \emph{Relevance of $Z$ by its ghost variable} is given by the relative
		      decrease in prediction accuracy in the test sample when $Z$ is replaced by
		      its ghost variable $\widehat{Z}$.
	\end{enumerate}
\end{algorithm}

\begin{note}
	The host variables approach to measure the effect of variable $Z$ combines
	the advantages of LOCO and random permutations:
	\begin{enumerate}
		\item The model is estimated only once.
		\item It gives results more similar to LOCO, which are better than those
		      obtained with random permutations when there are dependence among
		      covariates.
	\end{enumerate}
\end{note}

\begin{example}{Additive model}{}
	If $f$ is additive in $X$ and $Z$, under quadratic loss,
	the relevance of $Z$ by its ghost variable is given by:
	\begin{equation*}
		\mathds{E} \left[
			\left( f(X,\,Z) - f(X,\,\mathds{E}(Z \mid X)) \right)^2
			\right] =
		\mathds{E} \left[
			\left( s_2(Z) - s_2(\mathds{E}(Z \mid X)) \right)^2
			\right]
	\end{equation*}
	which does not coincide neither with LOCO nor with random permutations.

	If additionally there is linearity, $s_2(Z) = Z\beta_Z$, it is
	equal to:
	\begin{equation*}
		\beta_Z^2 \mathds{E} \left[
			\left( Z - \mathds{E}(Z \mid X)\right)^2
			\right] =
		\beta_Z^2 \mathds{E} \left[
			\text{Var}(Z \mid X)
			\right]
	\end{equation*}
	which coincides with LOCO in this case.
\end{example}

\begin{recap}{LOCO, random permutation and Ghost variables}{}
	\begin{itemize}
		\item It is desirable that any variable relevance method would
		      measure meaningful quantities when applied to simple models.
		\item We have seen that for \emph{multiple linear regression}
		      models:
		      \begin{itemize}
			      \item \emph{LOCO} and \emph{ghost variables} give
			            approximately the same results.
			      \item The relevance of variable $Z$ by LOCO and ghost
			            variable is proportional to the clasical
			            $F$-statistic used for testing $H_0: \beta_Z = 0$
			            against $H_1: \beta_Z \neq 0$.
			      \item The relevance by random permutations does not
			            reproduce any standard test statistic for the
			            significance of $\beta_Z$.
		      \end{itemize}
		\item We conclude that \emph{measuring variable relevance by ghost
			      variables combines the advantages of the other two methods}:
		      \begin{itemize}
			      \item The model is trained only once.
			      \item In linear regression it reproduces the significance
			            $F$-statistics.
		      \end{itemize}
		\item When we measure the relevance by ghost variable in a
		      predictive model, we are in some way
		      \emph{extending the concept of variable relevance} to
		      that model.
	\end{itemize}
\end{recap}

\subsection{Other relevance measures based on perturbations}
\index{perturbation}

Random permutations and ghost variables methods for computing
relevance of a explanatory variable $Z$ follow a general
scheme:
\begin{quote}
	To replace the values of $Z$ in the test set by ``perturbed'' values
	of them, which are independent of the response variable $Y$, given
	the other explanatory variables $X$.
\end{quote}

Other possibilities of ``perturbation'' of $Z$ have been considered
recently in the literature.

\subsubsection{Knockoffs}

Consider the lasso estimation of a linear model with
reponse variable $Y$ and explanatory variables
$\boldsymbol{X} = (X_1,\ldots,X_p)$ with large $p$.

When testing the significance of a large number of predictors
the problem of controlling the \iemph{false discovery rate} (FDR)
\index{FDR}
arises.

\begin{definition}{Knockoff variables}{} \index{knockoff}
	% TODO cite
	were defined by Barber and Candès (2015) as
	variables unrelated to the response and that jointly
	have the same distribution as the original ones,
	but being \emph{as different as possible} from them.
\end{definition}

Assuming that the explanatory variables $\boldsymbol{X}$ are
random variables with a known joint distribution, then
the set of \iemph{model-X} (MX)
\index{MX}
knockoff variables $\tilde{\boldsymbol{X}} = (\tilde{X}_1,\ldots,\tilde{X}_p)$,
are independents of $Y$ given $\boldsymbol{X}$, and the joint distribution of
\begin{equation*}
	(\boldsymbol{X},\,\tilde{\boldsymbol{X}}) =
	\left( X_1,\ldots,X_p,\,\tilde{X}_1,\ldots,\tilde{X}_p \right)
\end{equation*}
does not change if we interchange any subset of the original variables
and their knockoffs.

The lasso model is fitted with all $X_i$ and $\tilde{X}_i$ as
explanatory variables.

% TODO: continue next slide on knockoffs

\subsubsection{Estimated conditional distribution}

% TODO: cite
In the context of feature selection in complex predictive models,
Tansey et al. (2022) also deal with the problem of working with
an unknown conditional distribution $(Z \mid X = x)$, when
they describe the general \iemph{Holdout Randomized Test} (HRT)
\index{HRT}.

They model the conditional distribution of $(Z \mid X = x)$
as a \emph{mixture of univariate Gaussians}. They fix the
number of components as 5, then there are
$ 5 + 5  + (5 - 1) = 14$ conditional
parameters to estimate as functions of the $p$ values
of $x$.

% TODO: cite
Then, they propose to estimate the conditional distribution
of $(Z \mid X = x)$ following the proposal of Bishop (1996)
on \iemph{mixture density networks}.

This method uses a neural network with 14 neurons in the
output layer (one for each parameter), instead of having
just one output neuron as it happens when the goal is
to estimate expectation $\mathds{E}(Z \mid X = x)$.

\begin{note}
	The estimation of the conditional distribution models
	is a complicated task, requiring considerable computer effort.

	On the contrary, \emph{ghost variables} require only
	to estimate the conditional expectation using the regression model
	preferred by the user.

	If there are many variables, it may be better to use \emph{lasso}
	type estimation.
\end{note}

\begin{recap}{Knockoffs vs. ghost variables}{}
	\begin{itemize}
		\item Using ghost variables or using knockoffs to compute relevance of
		      features are comparable strategies regarding:
		      \begin{itemize}
			      \item the quality of the resulting relevance measures,
			      \item the computational efficiency.
		      \end{itemize}
		\item Both are preferred to other alternatives considered in our simulation
		      study.
		\item When using ghost variables the practitioner has to propose
		      regression models of each explanatory variable over the others, and
		      then fit these models.
		\item This is a routine process which is easily implemented in any standard
		      platform (R or Python, for instance), even if the linearity assumption
		      is not fulfilled by our data.
		\item On the other hand, generating knockoffs variables is difficult even in
		      the most standard settings.
		\item Moreover, when the data are far from well mimicked with Model-X
		      Gaussian knockoffs there is no easy way to generate knockoffs.
		\item Simplicity and flexibility of the ghost variable procedure are a clear
		      advantage with respect to using knockoffs.
	\end{itemize}
\end{recap}

\subsection{The relevance matrix}\index{relevance matrix}

We jointly measure the relevance of all the explanatory variables.

Given the random vector $(X,\,Y)$, $X = (X_1,\ldots,X_p) \in \mathds{R}^p$,
$Y \in \mathds{R}$, the prediction of $Y$ from the $p$ components of
$X$ through  the estimation of the regression function
$m(x) = \mathds{E}(Y \mid X = x)$ is considered.

A training sample $(\boldsymbol X_1, \boldsymbol y_1 ) \in \mathds R^{n_1 \times (p+1)}$
has been used to build an estimator $\widehat m(x)$ of $m(x)$.

An additional test sample $(\boldsymbol X_2, \boldsymbol y_2 ) \in \mathds R^{n_2 \times (p+1)}$
is available.

$\boldsymbol X_{2.\hat\jmath } = (\boldsymbol x_{2,1},\ldots,\boldsymbol x_{2.j-1}, \hat{\boldsymbol{x}}_{2.j}
	,\boldsymbol x_{2,j+1},\ldots,\boldsymbol x_{2,p}),\;j=1,\ldots,p$.

$\hat{\boldsymbol{y}}_2 = \widehat{m}(\boldsymbol X_{2}),\quad
	\hat{\boldsymbol{y}}_{2.\hat\jmath} = \widehat{m}(\boldsymbol X_{2.\hat\jmath})$.

\begin{definition}{Case-variable relevance matrix}{}\index{case-variable relevance matrix}
	\begin{equation*}
		\boldsymbol A = \left(
		\hat{\boldsymbol{y}}_{2} - \hat{\boldsymbol{y}}_{2.\hat 1},
		\ldots,
		\hat{\boldsymbol{y}}_{2} - \hat{\boldsymbol{y}}_{2.\hat p}
		\right)
	\end{equation*}
\end{definition}

\begin{definition}{Variable relevance matrix}{}\index{variable relevance matrix}
	\begin{equation*}
		\boldsymbol V = \frac{1}{n_2} \boldsymbol A^T \boldsymbol A
	\end{equation*}
	\tcblower

	In the diagonal of $\boldsymbol V$ we have:
	\begin{equation*}
		v_{jj} = \text{Rel}_{Gh}(X_j),\quad j=1,\ldots,p
	\end{equation*}

	Similarly, for random permutations: $\tilde{\boldsymbol{V}}$.
\end{definition}

\subsubsection{Comparing relevance matrices in linear regression}

Let $\boldsymbol S_2,\, \boldsymbol R$ and $\boldsymbol P$ be, respectively,
estimations of the covariance matrix, the correlation matrix, and the partial correlation matrix of
$X$ computed in the test sample.

\paragraph{Ghost variables}

\begin{align*}
	\boldsymbol V & = - \text{diag}\left(\hat\beta\right) \text{diag}\left(\hat\sigma_{[1]},\ldots,\hat\sigma_{[p]}\right)
	\boldsymbol P\text{diag}\left(\hat\sigma_{[1]},\ldots,\hat\sigma_{[p]}\right) \text{diag}\left(\hat\beta\right)        \\
	              & = \frac{n_2 - 1}{n_2}
	\text{diag}\left(\hat\beta\right) \text{diag}\left(\hat\sigma_{[1]}^2,\ldots,\hat\sigma_{[p]}^2\right)
	\boldsymbol S_2^{-1} \text{diag}\left(\hat\sigma_{[1]}^2,\ldots,\hat\sigma_{[p]}^2\right) \text{diag}\left(\hat\beta\right)
\end{align*}

\paragraph{Random permutation}

\begin{align*}
	\tilde{\boldsymbol V} & \approx
	2\text{diag}\left(\hat\beta\right) \text{diag}\left(S_1,\ldots,S_p\right) \boldsymbol R \text{diag}\left(S_1,\ldots,S_p\right) \text{diag}\left(\hat\beta\right) \\
	                      & = 2 \text{diag}\left(\hat\beta\right) \boldsymbol S_2 \text{diag}\left(\hat\beta\right)
\end{align*}

\begin{align*}
\end{align*}

\begin{note}
	In linear regression, $\boldsymbol V$ and $\tilde{\boldsymbol{V}}$ codify
	\emph{complimentary information}.
\end{note}


\subsection{Variable relevance measures as Shapley’s values}

Consider a linear regression model with response $y$ and explanatory
variables $x_1,\ldots,x_p$, estimated by OLS from the sample
$\{(x_i = (x_{i1},\ldots,x_{ip}),\,y_i)\}_{i=1}^n$.

Let $\bar y = \frac{1}{n} \sum_{i=1}^n y_i$ and $\hat y_i$ be the $i$-th fitted value.

A quality measure of the model is the coefficient of determination:
\begin{equation*}
	R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat y_i)^2}{\sum_{i=1}^n (y_i - \bar y)^2}
	\tag{Coefficient of determination}\index{coefficient of determination}
\end{equation*}

More over, $R^2$ is equal to the squared sampling correlation coefficient
between the observed responses $y_i$ and the fitted values $\hat y_i$.

When the $p$ explanatory variables are \emph{uncorrelated},
\begin{equation*}
	R^2 = \sum_{j=1}^p R_j^2
\end{equation*}
where $R_j^2$ is the coefficient of determination in the simple linear regression
of $y$ against the $j$-th explanatory variable $x_j$.

Therefore, $R_j^2$ is the contribution of $x_j$ to the global quantity measure
$R^2$, and it is a good measure of the relevance of $x_j$ in the model.

\begin{note}
	This decomposition is no longer true when the explanatory variables are
	correlated.
\end{note}

% TODO: cite properly (both Lipovetsky and Shapley)
Lipovetsky and Conklin (2001) propose an alternative decomposition of
$R^2$ based on the Shapley value. A useful tool coming from the
cooperative game theory.

\index{cooperative game}

A cooperative game with $p$ players, $P = \{1,\ldots,p\}$, is characterized
by a \iemph{payoff function} $v: 2^P \to \mathbb R$, such that for any coalition
of players $S \subseteq P$ the total payoff the members of $S$ can obtain is
$v(S)$.

It is assumed that $v(\emptyset) = 0$.

When all the players collaborate, the total payoff is $v(P)$.

The relevant question in cooperative games theory is to find a fair
distribution of $v(P)$ among the $p$ players, $\phi_i(v),\,i = 1,\ldots,p$.
Or, rephrasing, to determine the importance of each player to the
overall cooperation.

\subsubsection{Shapley value axiomatic definition}

Four desirable properties:
\begin{itemize}
	\item \textbf{Efficiency}: The global payoff is distributed among the players.
	      That is, the sum of the individual payoffs of all players equals the value of the grand
	      coalition, so that all the gain is distributed among the players:
	      \begin{equation*}
		      \sum_{i=1}^p \phi_i(v) = v(P)
	      \end{equation*}

	\item \textbf{Symmetry}: If $i$ and $j$ are two players who are equivalent
	      in the sense that:
	      \begin{equation*}
		      v(S \cup \{i\}) = v(S \cup \{j\})
	      \end{equation*}
	      for every subset $S \subseteq P \setminus \{i,j\}$, then $\phi_i(v) = \phi_j(v)$.
	      This property is also called ``equal treatment of equals''.

	\item \textbf{Linearity}: If two coalition games described by payoff functions
	      $v$ and $w$ are combined, then the distributed gains should correspond to the gains
	      derived from $v$ and the gains derived from $w$:
	      \begin{equation*}
		      \phi_i(v + w) = \phi_i(v) + \phi_i(w),\quad \forall i \in P
	      \end{equation*}
	      also, for any real number $a$:
	      \begin{equation*}
		      \phi_i(av) = a \phi_i(v),\quad \forall i \in P
	      \end{equation*}

	\item \textbf{Null player}: The payoff $\phi_i(v)$ of a \iemph{null player} $i$ in game $v$ is zero.
	      A player is ``null'' if $v(S \cup \{i\}) = v(S)$ for every subset $S \subseteq P \setminus \{i\}$.

\end{itemize}

\begin{theorem}{}{}
	The only distribution satisfying the four axioms above is the Shapley value of the game,
	defined as follows for the $j$-th player:
	\begin{equation*}
		\phi_j(v) = \sum_{S \subseteq P \setminus \{j\}} \frac{|S|! (p - |S| - 1)!}{p!} (v(S \cup \{j\}) - v(S))
	\end{equation*}

	\tcblower

	The quantity $\frac{|S|! (p - |S| - 1)!}{p!}$ is the \emph{marginal contribution} of
	the player $j$ to the coalition $S$. And, its Shapey value $\phi_j(v)$ is the
	average of these marginal contributions over the possible different permutations
	of the set $P$.

	An alternative expression for the Shapey value is: % cite e.g., Cohen, Dror, and Ruppin 2007
	\begin{equation*}
		\phi_j(v) = \frac{1}{p!} \sum_{\pi \in \Pi(P)}
		\left(
		v(S_j(\pi) \cup \{j\}) - v(S_j(\pi))
		\right)
	\end{equation*}
	where $\Pi(P)$ is the set of all permutations of $P$ and $S_j(\pi)$ is the
	set of players preceding $j$ in the permutation $\pi$.
\end{theorem}

Lipovetsky and Conklin (2001) propose to consider the cooperative game at which
the $p$ players are the explanatory variables.

For a subset $S$ of the $p$ predictors, the characteristic function $v(S)$ is
the coefficient of determination $R^2_S$ in the regression of $y$ against the
variables belonging to $S$.

Therefore, the Shapley value of this game is a fair distribution of the total
$R^2$ among the $p$ predictors:
\begin{equation*}
	R^2 = \sum_{j \in P} \phi_j(v)
\end{equation*}
and $\phi_j(v)$ measures the importance of the $j$-th regressor in the model.

Given that exact computation of Shapley values is quite time intensive,
Lipovetsky and Conklin (2001) suggest to average over
a moderate number of random permutation of the explanatory
variables. % TODO: cite

This average estimation is founded in  the second alternative expression
for $\phi_j(v)$, given above.

\begin{note}
	The computation of the Shapey value requires fitting the prediction model as many times as
	different subsets $v(S_j(\pi)$ and $v(S_j(\pi) \cup \{j\})$ are considered.

	This can be prohibitive with models with moderate or large fitting cost.
\end{note}

\subsection{Global graphical methods}

The general problem of graphically representing a function $f$
depending on $p$ variables, $x = (x_1,\ldots,x_p) \in \mathbb R^p$,
is not easy.

We present here several approaches that take into account that the function $f$ to be represented
is a prediction function estimated from a training set with data assumed to come from a
$p$-dimensional random variable $X$.

Availability of additional test set is also assumed.

We refer to either the training or the test set as $\{x_i\}_{i=1}^n$.

\subsubsection{Partial dependence plots (PDP)}\index{partial dependence plots}\index{PDP}

The PDP corresponding to the $j$-th variable aims to
represent the $j$-th \iemph{partial dependence profile function} $f_j(z)$ defined as:
\begin{equation*}
	f_j(z) = \mathds E \left[
		f(X_{(-j)},\,z)
		\right],\quad\forall z \in \left[
	x_{\min,j},\,x_{\max,j}
	\right]
\end{equation*}
where the notation $(X_{(-j)},\,z)$ refers to the $p$ dimensional random
vector having all the coordinates as $X$ except the $j$-th one, that is
constant and equal to $z$. Additionally, $x_{\min,j}$ and $x_{\max,j}$ are the
support of the $j$-th marginal of $X$.

The natural estimator of $f_j(z)$ is the average of the predictions:
\begin{equation*}
	\hat f_j(z) = \frac{1}{n} \sum_{i=1}^n f(x_{i(-j)},\,z)
\end{equation*}

Therefore, the $j$-th PDP is the graphical representation of the function $\hat f_j(z)$.

For an additive model $f(x) = \alpha_0 + \sum_{j=1}^p g_j(x_j)$, the $j$-th PDP
is the graph of $g_j(z) + C_j$, for some constant $C_j$.

\subsubsection{Local-dependence plots (LDP) or marginal plots}

When explanatory variables are not independent, much more interesting than
PDPs would be the plots representing the \iemph{conditional expectation functions}:
\begin{equation*}
	h_j(z) = \mathds E \left[
		f(X) \mid X_j = z
		\right]
\end{equation*}
because the relevant distribution of $X_{(-j)}$ when $X_j = z$ is not the
marginal distribution of $X_{(-j)}$ but the conditional distribution
$X_{(-j)} \mid X_j = z$.

The functions $h_j(z)$ can be estimated using any non-parametric
regression tool to smooth the scatter plot
\begin{equation*}
	\left(
	x_{ij},\,f(x_{i(-j)},\,x_{ij})
	\right) = \left(
	x_{ij},\,f(x_i)
	\right),\quad i = 1,\ldots,n
\end{equation*}

The graphical representation of the estimated functions $h_j(z)$ are known
as \iemph{local-dependence plots} or \iemph{marginal plots}.

\subsubsection{Accumulated Local Effects (ALE)}

Nevertheless, local-dependence plots are not fully satisfactory when there are
interactions between the explanatory variables in the
definition of $f$, because a problem of omitted variables can appear, as
pointed out by Apley and Zhu (2020). % TODO: cite

Consider, for instance, the function $f(x_1,\,x_2) = x_2 - 0.1x_1 x_2$ and
$(X_1,\,X_2)$ uniformly distributed in the set:
\begin{equation*}
	\mathcal U = \left\{
	\left|
	x_1 - x_2
	\right| \leq 0.1
	\right\} \cap \left(
	[0,\,1] \times [0,\,1]
	\right)
\end{equation*}

The local dependence function corresponding to the first explanatory variable is, for
$z \in [0,\,1,\,0.9]$, $h_1(z) = z - 0.1 z^2$ with
$h_1'(z) = 1 - 0.2 z > 0$. even if $f(x_1,\,x_2)$ is decreasing in $x_1$
for any $(x_1,\,x_2) \in \mathcal U$.

Apley and Zhu (2020) overcome this difficulty by introducing the
\iemph{accumulated local effects} (ALE) plots. \index{ALE}

\begin{definition}{ALE plot}{} for $p = 2$ variables

	The \iemph{local effect} of $x_1$ on $f$ at $(x_1,\,x_2)$ is computed as the partial
	derivative $f^1(x_1,\,x_2) = \partial f/\partial x_1$. Therefore:
	\begin{equation*}
		\mathds E \left[
			f^1(X_1,\,X_2)
			\mid X_1 = x_1
			\right] = \mathds E \left[
			f^1(x_1,\,X_2) \mid X_1 = x_1
			\right]
	\end{equation*}
	is the \iemph{conditional expected local effect} of $x_1$ on $f$.

	Then, the \iemph{accumulated local effect} of the first argument of $f$
	until the value $x_1$ is defined as:
	\begin{equation*}
		f_{1,\text{ALE}}(x_1) = \int_{x_{\min,1}}^{x_1} \mathds E \left[
			f^1(X_1,\,X_2)
			\mid X_1 = z
			\right] \, \mathrm d z
	\end{equation*}
	where $x_{\min,1}$ is the lower bound of the support of $X_1$.

	The \emph{ALE plot} is the graphical representation of
	$(x_1,\,f_{1,\text{ALE}}(x_1))$ for $x_1 \in [x_{\min,1},\,x_{\max,1}]$.

\end{definition}

\begin{example}{ALE for an additive model}{}
	$f(x_1,\,x_2) = \alpha_0 + g_1(x_1) + g_2(x_2)$, the
	conditional expected local effect of $x_1$ at $f$ is equal to $g_1'(x_1)$ and the
	ALE plot is $(x_1,\,g(x_1) + C)$ for $C = -g_1(x_{\min,1})$.
\end{example}

\begin{example}{ALE for a linear function}{}
	$f(x_1,\,x_2) = \beta_0 + \beta_1 x_1 + \beta_2 x_2$, the
	conditional expected local effect of $x_1$ at $f$ is equal to $\beta_1$ and the
	ALE plot is $(x_1,\,\beta_1 x_1 + C)$ for $C = -\beta_1 x_{\min,1}$.
\end{example}

\begin{note}
	These 3 methods (PDP, LDP and ALE) could provide
	different results when dependence between the explanatory variables
	and/or interaction effects are present.

	In this case, the recommendation is to explore these causes and take
	them into account.
\end{note}

% \subsection{Importance of variables through disturbances}
% \subsection{Importance based on the Shapley Value}
% \subsection{Partial dependency graph}
% \subsection{Cumulative local effects graphs}

\section{Local methods}

This section is devoted to model-agnostic methods that provide
explanations for a single prediction $f(x)$ of a non-transparent model
$f$.

Most of the local explanation methods have a common structure: a
simple interpretable method $g$ is fitted locally around $x$ in such a
way that $g(x') \approx f (x')$ when $x'$ is in a neighborhood of $x$.

Then it is expected that the available interpretation of $g$ remains
valid for $f$ around $x$.

This general approach (called \iemph{explanation by simplification} by
Barredo-Arrieta et al. 2020) has certain similarities to local
polynomial fitting in non-parametric regression (see, e.g., Fan and
Gijbels 1996).

\subsection{LIME: Local interpretable model-agnostic explanations}
\index{LIME}
\index{local interpretable model-agnostic explanations}

% TODO: cite
Among the methods of explanation by simplification, Local
Interpretable Model-agnostic Explanations (LIME, Ribeiro, Singh,
and Guestrin 2016) is probably the most popular one.

In LIME, $d \ll p$ easily recognizable properties of $x$ are selected
(e.g., if $x$ is a car image, a property can be the presence of a wheel
in the image; if $x$ is a text, a property could be the presence of a
certain key word), and their influence in the prediction $f (x)$ is
explored.

The simple interpretable model $g$ is assumed to take values in
$d$-dimensional space, and only $z \in \{0,\, 1\}^d$ are allowed as arguments
of $g$.

Let $\mathcal G$ be the class of models to which $g$ belongs to (for instance, $\mathcal G$
can be the class of linear models with $d$ explanatory variables).

Additionally, a one-to-one application $h_x$ is established between the
elements in $\{0,\, 1\}^d$ and $2^d$ neighbors $x' \in \mathds R^p$ of $x$.

For $r = 1, \ldots , d,\; z_r = 1$ means that $h_x (z)$ shares the $r$-th selected
property with $x$. It is assumed that $h_x (1_d) = x$, where $1_d$ is the
vector of ones in $\mathds R^d$.

\begin{note}
	The definition of $h_x$ is specific for each problem at hand.
\end{note}

\begin{example}{Possible definitions for $h_x$}{}

	For instance, when $x$ is a text and the selected properties are the
	presence of $d$ chosen key words contained in $x$, $h_x (z)$ returns the
	text $x$ without the key words for which $z_r = 0$.

	If $x$ is a car image, and the $r$-th property is the presence of a
	super-pixel contained in $x$ showing a wheel, for a $z$ with $z_r = 0$ the
	function $h_x (z)$ will return the same image $x$ with the wheel
	super-pixel replaced by gray colored pixels.
\end{example}

A sufficiently large number $N \leq 2^d$ of random points $z \in \{0,\, 1\}^d$ are
chosen, and the pairs $\left(z_k,\, f(h_x(z_k)) \right),\; k = 1, \ldots , N$ are annotated.

The explanation produced by LIME to the prediction $f(x)$ is:
\begin{equation*}
	g_x = \arg \min_{g \in \mathcal G} \left\{
	\sum_{k = 1}^N L \left(g(z_k),\, f(h_x(z_k)) \right) \boldsymbol \pi_x(h_x(z_k)) + \boldsymbol\Omega(g)
	\right\}
\end{equation*}
where $L(y,\,y')$ is a \iemph{loss function} measuring how different the real numbers $y$ and
$y'$ are, $\boldsymbol \pi_x(x')$ is a \iemph{proximity measure} between $x$ and $x'$
(as the kernel function used in non-parametric regression), and $\boldsymbol\Omega(g)$ is a
\iemph{measure of complexity} of the models belonging to $\mathcal G$.

\begin{note}
	Not every $g\in\mathcal G$ may be equally interpretable.

	For instance, for linear models $\boldsymbol\Omega(g)$ can be
	a $L_1$ penalty term in order to favor sparse solutions, as in LASSO estimation.
\end{note}

\begin{example}{}{}
	In practical examples, Ribeiro, Singh, and Guestrin (2016) apply LIME
	with:
	\begin{itemize}
		\item Quadratic loss $L(y,\,y') = (y - y')^2$.
		\item Gaussian kernel $\boldsymbol \pi_x(x') = \exp \left( -\frac{1}{2\sigma^2} \|x - x'\|^2 \right)$.
		\item Linear models as $\mathcal G$.
		\item LASSO estimation (or least squares after having selected $K < d$ variables
		      by LASSO).
	\end{itemize}

	Using these settings, the LIME explanation $g_x$ for $f(x)$ consists on
	the selection of $K$ properties among the $d$ that originally were of
	interest, plus the corresponding estimated coefficients.
\end{example}

\begin{note}
	LIME is more a general methodology than a specific method for local
	explanation.
\end{note}

However, many details have to be tuned before LIME can be applied to a
specific problem:
\begin{itemize}
	\item Class of models
	\item Loss function
	\item Proximity function
	\item Penalty term
	\item Number $K$ of selected properties among the $d$ variable.
	\item How many properties $d$ to choose and how are they chosen
	\item How to fix the sample size $N$.
	\item How to define the one-to-one function $h_x$.
\end{itemize}

\subsection{Local importance based on the Shapley Value}

% TODO: cite
Štrumbelj and Kononenko (2010) present a general method for
explaining individual predictions of classification models, based on
Shapley values.

Their proposal extends easily to regression problems.

Given an instance $x$, the goal is to explain how its feature values
$(x_1,\ldots,x_p)$ contribute to the prediction difference between $f(x)$ and
the expected prediction if no feature values are known.

They consider the framework of a
cooperative game at which the $p$ players are the observable features.

Assuming that the feature values are random observations of a
$p$-dimensional random variable $X$, the characteristic function
proposed is $v_x (\emptyset) = 0$ and, for
any nonempty subset $S$ of $P = \{1,\ldots,p\}$,
\begin{equation*}
	v_x(S) = \mathds E (f (X) \mid X_S = x_S) − \mathds E (f (X))
\end{equation*}
where $x_S$ is the vector containing the coordinates of $x$ with indices
in $S$ (similarly for $X_S$).

Using the same arguments and notation as in the global relevance
problem, the Shapley value of this game for feature $j$ is:
\begin{equation*}
	\phi_j(v_x) = \frac{1}{p!} \sum_{\boldsymbol \pi \in \Pi(P)} \biggl(
	\mathds E \left[
			f(X) \mid X_{S_j(\boldsymbol \pi) \cup \{j\}} = x_{S_j(\boldsymbol \pi) \cup \{j\}}
			\right]
	- \mathds E \left[
			f(X) \mid X_{S_j(\boldsymbol \pi)} = x_{S_j(\boldsymbol \pi)}
			\right]
    \biggr)
\end{equation*}

Observe that
\begin{equation*}
    f(x) = \mathds E(f(X)) + \sum_{j = 1}^p \phi_j(v_x)
\end{equation*}
because the sum of all the Shapley values is equal to
$v_X(P) = f(x) - \mathds E(f(X))$.

Therefore, $\phi_j(v_x)$ is effectively measuring how the $j$-th feature of $x$ is
contributing to move the prediction from the information-less prediction
$\mathds E(f(X))$ to the actual prediction $f(x)$.

In order to give a feasible version of Shapley value, a sampling approach is needed.
% TODO: there are two slides explaining the approach.

\subsection{SHAP: SHApley Additive ExPlanations}
\index{SHAP}

% TODO: cite
Lundberg and Lee (2017) propose a method for local explanations, that they call
SHAP (\iemph{SHApley Additive ExPlanations}), unifying six existing methods.
Among them, LIME and Shapley value based local explanations.

The SHAP framework has several common elements with LIME:
\begin{itemize}
    \item A number $d \ll p$ of properties of $x$ are selected (here they are called
        \iemph{simplified input features}) for which presence-absence is codified
        as a vector $z \in \{0,\,1\}^d$.
    \item A local one-to-one function $h_x$ is defined from $\{0,\,1\}^d$ to the
        neighborhood of $x$ in $\mathds R^d$.
    \item An explanation model $g(z)$ is fitted, which in this case is linear:
        \begin{equation*}
            g(z) = \phi_0 + \sum_{r = 1}^d \phi_r z_r
        \end{equation*}
\end{itemize}

\subsection{Break down graphics}
\subsection{ICE: Individual conditional expectation, or ceteris paribus chart}
